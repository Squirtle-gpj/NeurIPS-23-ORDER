discount: 0.99
hidden_dim: 256
n_hidden: 2
n_steps: 1000000
batch_size: 512
learning_rate: 0.0003
alpha: 0.05
tau: 0.7
beta: 3.0
eval_period: 5000
n_eval_episodes: 10
max_episode_steps: 1000


sample_seq_length: 64
action_embedding_size: 16 # 0
observ_embedding_size: 32
reward_embedding_size: 16 # 0
rnn_hidden_size: 128
dqn_layers: [256, 256]
policy_layers: [256, 256]
grad_norm: 1.0

log_period: 1000
save_period: 200000
